from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
import os

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
loader = DirectoryLoader(path="data/rag_docs", glob="**/*.md")
docs = loader.load()
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")

# 2. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = splitter.split_documents(docs)
print(f"‚úÇÔ∏è –ß–∞–Ω–∫–æ–≤ –ø–æ–ª—É—á–µ–Ω–æ: {len(chunks)}")

# 3. –ü–æ–ª—É—á–∞–µ–º embedding —á–µ—Ä–µ–∑ MiniLM
print("ü§ñ –ü–æ–ª—É—á–∞–µ–º embedding —á–µ—Ä–µ–∑ MiniLM (HuggingFace)...")
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º FAISS
index_path = "faiss_index"
if os.path.exists(index_path):
    db = FAISS.load_local(index_path, embedding, allow_dangerous_deserialization=True)
    print("üîÅ –ò–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω.")
else:
    db = FAISS.from_documents(chunks, embedding)
    db.save_local(index_path)
    print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω!")
