from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.llms import Ollama
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA

import os

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
loader = DirectoryLoader(path="data/rag_docs", glob="**/*.md")
docs = loader.load()
print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(docs)}")

# 2. –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
chunks = splitter.split_documents(docs)
print(f"‚úÇÔ∏è –ß–∞–Ω–∫–æ–≤ –ø–æ–ª—É—á–µ–Ω–æ: {len(chunks)}")

# 3. –ü–æ–ª—É—á–∞–µ–º embedding —á–µ—Ä–µ–∑ Ollama
print("ü§ñ –ü–æ–ª—É—á–∞–µ–º embedding —á–µ—Ä–µ–∑ Ollama...")
embedding = OllamaEmbeddings(model="mistral")

# 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–ª–∏ –∑–∞–≥—Ä—É–∂–∞–µ–º FAISS
index_path = "faiss_index"

if os.path.exists(index_path):
    print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS...")
    vectorstore = FAISS.load_local(index_path, embedding, allow_dangerous_deserialization=True)
else:
    print("üß± –°—Ç—Ä–æ–∏–º –∏–Ω–¥–µ–∫—Å FAISS...")
    vectorstore = FAISS.from_documents(chunks, embedding)
    vectorstore.save_local(index_path)
    print("‚úÖ –ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω!")

# 5. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LLM + Retrieval Chain
print("üß† –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º LLM –∏ RetrievalQA...")
llm = Ollama(model="mistral")
qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())

# 6. –î–∏–∞–ª–æ–≥
print("\n‚úÖ –ì–æ—Ç–æ–≤–æ! –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
while True:
    question = input("\nüîπ –í–æ–ø—Ä–æ—Å: ")
    if question.lower() in ["exit", "quit"]:
        print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        break
    answer = qa_chain.run(question)
    print(f"\nüí¨ –û—Ç–≤–µ—Ç:\n{answer}")
